\documentclass[letterpaper,12pt]{article}

% \usepackage{graphicx}
\usepackage[hmargin=3cm,vmargin=3.5cm]{geometry}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{microtype}

\title{Facilitator project report}
\author{Hans Chen}
\date{}

\pagestyle{fancy}

\fancyhead{}
\fancyhead[l]{Facilitator project report}
\fancyhead[R]{Hans Chen}


\begin{document}

\begin{center}
    \large Enhancing concise scientific writing and conceptual understanding in Earth system science
\end{center}

\section{Introduction}

I teach an Earth system science course for first-year Bachelor students in the Global Systems program.
This course focuses on developing students' ability to understand and describe Earth system processes from a systems perspective,
both qualitatively and quantitatively.


The main teaching and learning activities (TLAs) consist of lectures,
calculation exercises,
and assignments.
In the lectures,
students explore different Earth system components,
the key processes within each component,
and interactions among components.
In the calculation exercises,
students apply quantitative methods to solve problems related to lecture content.
Additionally,
students complete three assignments in which they run and develop simple Earth system models,
with support from three dedicated help sessions.

The course assessment comprises two components:
the submitted assignments and a final  written exam at the end of the course.
The assignments primarily address one specific intended learning outcome (ILO)
and constitute a separate course component with independent grading;
they will not be the focus of this report.
The written exam consists of single-choice questions ($\sim$20\%),
written explanations ($\sim$50\%),
and calculations problems ($\sim$30\%).


\section{Challenge}

A significant portion of the assessment---%
about half of the final exam---%
is based on written answers,
yet there is a lack of TLAs that specifically target this skill.
We have observed that some students struggle with providing concise and direct answers to questions.
Perhaps as a carry-over from high school,
some students write overly long answers when unsure,
attempting to hit upon the right keywords to earn points.

To address this,
we emphasize during both lectures and in the final exam that we are looking for short, concise answers to the questions,
and that we grade based not only on the presence of keywords but also on the clarity and coherence of the explanation.
We often provide an indication of the expected answer length.
The sample answers to old exam questions that we share with students are rarely more than a few sentences long.

Furthermore,
we dedicate part of a lecture to practicing exam-type questions,
where we demonstrate how to formulate effective answers.
During another lecture,
students participate in an in-class activity where they practice explaining different concepts to each other.
Nevertheless,
these activities are conducted orally,
and students never receive hands-on practice or feedback on written explanations.


\section{Aim}

The aim of this facilitator project is to introduce a set of TLAs that specifically target the development of students' scientific writing skills,
particularly their ability to formulate direct, concise answers to scientific questions.

Through these TLAs,
I also aim to clarify our expectations for written answers on the final exam and help students understand how these answers are graded.
An additional objective is to use the writing activities not only to train students in writing,
but also to deepen their mastery and understanding of the course content.


\section{Proposed solution}

The proposed solution consists of four sequential TLAs designed to address these challenges.
Upon completion of these TLAs, students should be able to:
(1) demonstrate scientific understanding of the course material through short written answers, and
(2) explain scientific concepts concisely without including irrelevant information.


\subsection{TLA1: Rate sample answers}

Before class,
students will be provided with sample questions and example answers of varying quality,
accompanied by the grading rubric used for assessment.
The task is to evaluate and grade the sample answers using the provided rubric.
After submitting their grading,
students will see the instructor's grades along with written explanations of the grading decisions.

The aim of this TLA is to clarify the grading criteria,
provide examples of both strong and weak answers,
and expose students to the instructor's perspective on assessment.
This TLA will be carried out asynchronously on the online learning platform Canvas.


\subsection{TLA2: In-class demonstration}

During class,
the instructor will present statistics from the TLA1 grading activity,
showing the distribution of student grades for each sample answer.
The instructor will then discuss their own grading decisions,
particularly for  questions where student evaluations varied widely.
Next,
the instructor will introduce a new question and demonstrate,
step by step,
how to break it down and formulate an effective answer.

One of the purposes of showing the TLA1 statistics is to make the students feel seen and that their efforts are valued,
in addition to highlighting any lack of consensus about what constitutes a strong answer.
This discussion helps make grading criteria more transparent and concrete.

The objective of the in-class demonstration is to explicitly model a systematic approach to formulating answers.
While students have likely developed strategies for answering questions during their previous education,
some of these habits may be ineffective for scientific writing.
During this demonstration,
it is important to emphasize that the approach shown is one effective method,
but that students may develop their own strategies that work best for them.


\subsection{TLA3: Write and peer-review}

Following TLA2,
students work in groups of 3--4 to formulate written answers to provided sample questions.
As this TLA focuses on developing the writing process rather than testing content knowledge,
students are permitted to consult lecture materials,
the course textbook,
and other resources.
However,
AI-based tools are prohibited to ensure that students develop their own writing skills.

After formulating individual answers,
students are provided with the grading rubric and asked to assess each other's answers within their groups.
Based on this peer review,
each group discusses the strengths and weaknesses of different approaches and collaboratively develops an agreed-upon ``best'' answer.

This TLA exposes students to multiple approaches to answering the same question.
By evaluating alternative formulations,
students practice identifying which content is essential,
what constitutes irrelevant detail,
and how wording and structure affect clarity.

Different groups will be given different questions.
To maximize learning across the entire class,
all first-attempt answers,
group evaluations,
and final answers (with instructor feedback) will be shared anonymously on Canvas after the session.
This allows groups to learn from each other's work.
Students may opt out of sharing their personal answers;
in that case,
they will not be able to access other students' personal answers either.


\subsection{TLA4: Personal reflection}

Finally,
students will be asked to write a personal reflection on the previous activities.
Some guiding questions include:
What was the most valuable thing you learned?
What, if anything, surprised you?
Did you notice any common mistakes in your group's answers, and how did you address them?

The reflection is intended to consolidate learning by encouraging students to articulate what they have learned
and how they will apply it in the future.
It also supports metacognitive development by prompting students to identify their own patterns and improvement strategies.

In addition,
there will be a specific section where students are asked to provide both quantitative and qualitative feedback on the effectiveness of these TLAs,
which will contribute to the project's evaluation strategy.


\subsection{Integration within the course}

These TLAs are likely to be most effective when students have relatively high mastery of the course material.
Therefore,
they will be implemented toward the end of the course.

Placing the activities close to the final exam could increase student motivation as a way to prepare for the exam.
Moreover,
it creates a buffer period between the final content delivery and the exam,
giving students additional time to consolidate their understanding and seek clarification if needed before the assessment.

This year,
the course content has been slightly reduced and one 2-hour lecture block has been removed.
These TLAs can therefore be introduced as a new seminar session without increasing the overall student workload.


\section{Evaluation strategy}


Evaluating the effectiveness of the TLAs in improving concise scientific writing is not straightforward,
because performance on the final exam also depends on content mastery.
Nevertheless, multiple evaluation approaches will be employed.

One practical process indicator is how often students request clarification about how written answers are graded.
Currently,
one or two students typically ask whether ``wild guesses'' can negatively affect their score.
By explicitly teaching that irrelevant information---%
not uncertain attempts---%
leads to lower scores,
students should better understand that tentative answers are acceptable,
but adding irrelevant information to a correct answer can reduce the grade.
A decrease in such questions would suggest improved understanding of grading expectations.

A more direct approach would be to compare scores on written answer questions before and after implementing these TLAs.
This comparison could extend beyond the current course to include the parallel course running simultaneously and subsequent courses in the program.
However,
this metric has significant limitations,
such as year-to-year variation in student cohorts,
differences in content mastery,
and varying exam questions.
Therefore,
the differences may not be significant even if the TLAs are effective.

A third source of evidence will be the submitted reflections from TLA4,
which can provide both quantitative metrics (e.g., rating the activities on a scale of 1--5 for usefulness)
and qualitative insights through written responses.
These reflections will reveal what students perceive they have learned,
which aspects of the TLAs were most valuable,
and how the activities influenced their approach to scientific writing.


\section{Discussion}

The assessment of these TLAs will be formative and focus on the learning process rather than performance outcomes.
Students must complete TLA1,
submit their group responses in TLA3,
and submit a personal reflection in TLA4 to receive credit.
Grading will be binary,
either ``pass'' if all components are submitted,
or ``incomplete'' if any component is missing.

At this stage,
I am hesitant to make participation fully mandatory.
Instead,
I am considering awarding a small number of bonus points on the final exam for completion.
If bonus points are introduced,
the course ILOs and exam design would need to be reviewed to ensure that students still demonstrate achievement of all ILOs
when achieving a passing grade with the bonus points.
A possible solution is to make the bonus points only count toward higher grades.

I have considered whether to implement these TLAs multiple times throughout the course.
Repeating the activities could increase efficiency,
as students would spend less time understanding the TLA structure and more time on the learning process itself after the first time.
However,
given the time constraints within the course and the challenge of maintaining student motivation across multiple iterations,
a single implementation seems most feasible.
If the evaluation demonstrates effectiveness,
similar TLAs could be implemented across courses at the program level.

In summary,
this facilitator project has developed a sequence of TLAs designed to help students write concise answers to scientific questions
while simultaneously deepening their understanding of course content through the writing process.
As the course runs in study period 4 and has not yet been offered again at the time of this writing,
implementation,
evaluation,
and reflection remain as next steps.

\end{document}
